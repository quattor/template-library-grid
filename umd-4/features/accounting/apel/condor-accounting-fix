#!/usr/bin/python
# re-write blah logs with hostname included with job id
# convert condor history file to PBS style accounting log file for consumption by APEL parser
#
# Author: sartiran@llr.in2p3.fr
#
# Minimal modification of an original script by Andrew Lahiff
#
# https://github.com/alahiff/cream-for-htcondor
#

from xml.etree import ElementTree
import sys
import subprocess
import glob
import grp, pwd
from datetime import datetime, timedelta
import socket
import time
import re
import argparse
import os

#for file in files:

#This adds the hostname to the job ids in the blah file
def fixBlahFile(file,outFile):
   print "opening ",file," for reading"

   fi = open(file, 'r')
   lines = fi.readlines()

   #outFile = '/var/apel/accounting/'+((file.split('/'))[len(file.split('/'))-1])
   f = open(outFile,'w')
   print 'writing to ',outFile

   LINE_EXPR = re.compile(r'\"|\"_\"')

   for line in lines:
      parts = [x.split('=',1) for x in [y for y in LINE_EXPR.split(line) if len(y) > 1]]
      record = ''
      for part in parts:
         if part[0] == 'lrmsID':
            part[1] = "%s.%s" % (part[1], socket.gethostname())
         if len(record) > 2:
            record = record + ' '
         record = record + '"' + part[0] + '=' + part[1] + '"'
      record = record + "\n"
      f.write(record)

   f.close()
   fi.close()

# Useful function
def getValue(node):
   for bit in node.getchildren():
      text = bit.text
   return text

# Convert time in seconds to HH:MM:SS such that HH can be > 24 if necessary
def tisToString(tis):
   (days, rem1) = divmod(tis, 86400)
   (hours, rem2) = divmod(rem1, 3600)
   (mins, rem3) = divmod(rem2, 60)
   hours = hours + days*24
   return '%02d:%02d:%02d' % (hours, mins, rem3)


def condorToPBS(file,outFile):
   print "opening ",file," for reading"

   # Read in XML output from condor_history
   p = subprocess.Popen(["condor_history", "-xml", "-file", file], stdout=subprocess.PIPE)
   output, err = p.communicate()
   document = ElementTree.fromstring(output)

   #outFile = '/var/apel/accounting/'+((file.split('/'))[len(file.split('/'))-1].replace('history.','condor-'))
   f = open(outFile,'a')
   print 'writing to ',outFile

   data = {}
   count = 0
   ecount = 0

   # List of required attributes
   req = ['ClusterId', 'ProcId', 'GlobalJobId', 'Owner', 'AcctGroup', 'ExitStatus', 'LastRemoteHost', 'RequestCpus', 'RequestMemory', 'QDate', 'JobStartDate', 'CompletionDate', 'RemoteUserCpu', 'RemoteSysCpu', 'RemoteWallClockTime' ,'ResidentSetSize_RAW', 'ImageSize_RAW', 'DiskUsage_RAW', 'NumJobStarts', 'NumShadowStarts' ]

   for job in document.findall( 'c' ):
      for bit in job.findall( 'a' ):
         attr = bit.attrib[ 'n' ]
         for item in req:
            if attr == item:
               data[item] = getValue(bit)

      if len(data) == 20:
         count = count + 1

         groups = [g.gr_name for g in grp.getgrall() if data['Owner'] in g.gr_mem]
         try:
            gid = pwd.getpwnam(data['Owner']).pw_gid
            group = grp.getgrgid(gid).gr_name
         except KeyError:
            group = "unknown"

         #scaling = float(data['MATCH_EXP_MachineRalScaling'])
         scaling = 1
         cputime_raw = float(data['RemoteUserCpu']) + float(data['RemoteSysCpu'])
         walltime_raw = float(data['RemoteWallClockTime'])

         cputime = tisToString(int(scaling * cputime_raw))
         walltime = tisToString(int(scaling * walltime_raw))

         mem = "%skb" % data['ResidentSetSize_RAW']
         vmem = "%skb" % data['ImageSize_RAW']

         try:
            host = (data['LastRemoteHost'].split('@'))[1]
         except:
            host = data['LastRemoteHost']

         exec_host = ""
         for i in range(int(data['RequestCpus'])):
            if i > 0:
               exec_host = exec_host + "+"
            exec_host = exec_host + "%s/%d" % (host, i)

         unused_date = time.strftime('%m-%d-%Y %H:%M:%S', time.localtime(int(data['CompletionDate'])))

         record = "%s;E;%s.%s;user=%s group=%s start=%s end=%s resources_used.cput=%s resources_used.walltime=%s resources_used.mem=%s resources_used.vmem=%s exec_host=%s\n" % (unused_date, data['ClusterId'], socket.getfqdn(), data['Owner'], group, data['JobStartDate'], data['CompletionDate'], cputime, walltime, mem, vmem, exec_host)

         f.write(record)

      else:
         ecount = ecount + 1

   print 'Read',count,'records from file ',file,' with ',ecount,' errors'

   f.close()

usedate = datetime.now() - timedelta(days=1)

parser = argparse.ArgumentParser(description='Process Condor logs for accounting purpose.')
parser.add_argument('--date', default='%d%02d%02d' % (usedate.year, usedate.month, usedate.day),
                   help='date of the logs to be parsed (default is yesterday)')
parser.add_argument('--blah-dir', default='/var/log/accounting/',
                   help='directory of the blah logs (default is /var/log/accounting/)')
parser.add_argument('--fixed-blah-dir', default='/var/apel/accounting/',
                   help='directory of the fixed blah logs (default is /var/apel/accounting/)')
parser.add_argument('--history-dir', default='/var/lib/condor/spool/',
                   help='directory of the condor history logs (default is /var/lib/condor/spool/)')
parser.add_argument('--pbs-dir', default='/var/lib/condor/server_priv/accounting/',
                   help='directory of the pbs history logs (default is /var/lib/condor/server_priv/accounting/)')
parser.add_argument('--done-blah', default='/var/lib/condor/server_priv/done',
                   help='list of fixed blah files (default is /var/apel/done)')
parser.add_argument('--done-condor', default='/var/lib/condor/server_priv/done',
                   help='list of fixed condor files(default is /var/lib/condor/server_priv/done)')


args = parser.parse_args()
usedate=datetime.strptime(args.date, '%Y%m%d')
yesterday = '%d%02d%02d' % (usedate.year, usedate.month, usedate.day)
#usedate = usedate  + timedelta(days=1)
#today = '%d%02d%02d' % (usedate.year, usedate.month, usedate.day)


fixBlahFile(args.blah_dir+'/blahp.log-'+yesterday,args.fixed_blah_dir+'/blahp.log-'+yesterday);

files = glob.glob(args.history_dir+'/history.'+yesterday+'*')
files.sort(key=lambda x: os.stat(x).st_mtime)
for logfile in files:
   condorToPBS(logfile, args.pbs_dir+'/'+yesterday)

